---
title: "Practical Machine Learning Project: Human Activity Recognition"
author: "by M. Grossi"
output: html_document
---

## Introduction

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is **quantify how much of a particular activity they do**, but they rarely **quantify how well they do it**. 

In this project, we will use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to predict the manner in which the exercises were performed. For more information see <http://groupware.les.inf.puc-rio.br/har> (section on the Weight Lifting Exercise Dataset). 

Reference: 
Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.

## Input Data Set 

The training data for this project are avalaible here:
<https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv>

The test data are available here:
<https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv>

 
I use the following libraries for this project: (set seed for consistent results)
```{r, result='hide'}
suppressMessages(library(caret))
suppressMessages(library(randomForest))
suppressMessages(library(gbm))
suppressMessages(library(AppliedPredictiveModeling))
suppressMessages(library(MASS))
suppressMessages(library(plyr))
suppressMessages(library(dplyr))
set.seed(123)
```

As a first step, I download and read the training and testing data sets:
```{r,echo=TRUE}
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
train_filename <- "./data/pml-training.csv"
test_filename  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
  dir.create("./data")
}
if (!file.exists(train_filename)) {
  download.file(trainUrl, destfile=train_filename, method="curl")
}
if (!file.exists(test_filename)) {
  download.file(testUrl, destfile=test_filename, method="curl")
}
# Load data
training_all <- read.csv(train_filename)
testing <- read.csv(test_filename)
dim(training_all) ; dim(testing)
```

I then split the training set in a pure training and a validation data set.
```{r, echo=TRUE}
# create validation data set
inTrain <- createDataPartition(training_all$classe, p = 0.70, list= FALSE)
training <- training_all[ inTrain, ]
validation <- training_all[-inTrain, ]
dim(training) ; dim(validation)
```


## Feature selection

The second step is to choose the features to be used in the prediction model. To this end I removed columns which contains mostly missing values, variables with nearly zero variance and variables which do not add valuable information to predict how the excercise was executed. 
```{r,echo=TRUE}
# remove missing values
mostlyNAN <- sapply(training, function(x) mean(is.na(x))) > 0.8
training <- training[, mostlyNAN==FALSE]
# remove near zero covariates
nzv <- nearZeroVar(training)
training <- training[, -nzv]
# remove id, user_name, timestamp
training <- training[,-(1:5)]
dim(training)
```

## Prediction Algorithms

I fit (1) a random forest predictor ("rfModel" ) relating the "classe" variable to the remaining variables, (2) a boosted trees predictor ("gbmModel) and finally (3) a linear discriminant analysis model ("ldaModel"). I use the train() command in the caret package.

```{r, echo=TRUE}
# Random Forest 
fitControl <- trainControl(method="cv", number = 3, verboseIter = FALSE)
rfModel  <- train(classe ~ ., method = "rf",  data = training, verbose = FALSE,trControl = fitControl, ntree = 250)
# Boosted Trees
gbmModel <- train(classe ~ ., method = "gbm", data = training, trControl = fitControl, verbose = FALSE)
# Linear Discriminant Analysis
ldaModel <- train(classe ~ ., method = "lda", data = training, verbose = FALSE)
```


## Model Evaluation

I evaluate the accuracy of the different prediction models on the validation data set.
```{r, echo=TRUE}
# Compute accuracy of the 3 Models
pred_rf <- predict(rfModel, validation)
pred_gbm <- predict(gbmModel, validation)
pred_lda <- predict(ldaModel, validation)
rf_a <- confusionMatrix(pred_rf, validation$classe)$overall[1]
gbm_a <- confusionMatrix(pred_gbm, validation$classe)$overall[1]
lda_a <- confusionMatrix(pred_lda, validation$classe)$overall[1]
print (c(rf_a,gbm_a,lda_a))
```

## Predictions for test data

Finally, I compute the predictions for the test set (random forest predictor):
```{r, echo=TRUE}
pred_rf_test <- as.character(predict(rfModel, testing))
print (pred_rf_test)
```


